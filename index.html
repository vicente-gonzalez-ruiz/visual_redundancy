<!DOCTYPE html> 
<html lang='en-US' xml:lang='en-US'> 
<head> <title>Visual Redundancy</title> 
<meta charset='utf-8' /> 
<meta content='TeX4ht (https://tug.org/tex4ht/)' name='generator' /> 
<meta content='width=device-width,initial-scale=1' name='viewport' /> 
<link href='index.css' rel='stylesheet' type='text/css' /> 
<meta content='index.tex' name='src' /> 
<script>window.MathJax = { tex: { tags: "ams", }, }; </script> 
 <script async='async' id='MathJax-script' src='https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js' type='text/javascript'></script>  
</head><body>
   <div class='maketitle'>
                                                                  

                                                                  
                                                                  

                                                                  

<h2 class='titleHead'>Visual Redundancy</h2>
 <div class='author'><span class='ecrm-1200'>Vicente González Ruiz</span></div><br />
<div class='date'><span class='ecrm-1200'>July 2, 2022</span></div>
   </div>
   <h3 class='likesectionHead' id='contents'><a id='x1-1000'></a>Contents</h3>
   <div class='tableofcontents'>
    <span class='sectionToc'>1 <a href='#statistical-redundancy' id='QQ2-1-2'>Statistical redundancy</a></span>
<br />    <span class='sectionToc'>2 <a href='#temporal' id='QQ2-1-3'>Temporal</a></span>
<br />    <span class='sectionToc'>3 <a href='#spatial-d' id='QQ2-1-4'>Spatial (2D)</a></span>
<br />    <span class='sectionToc'>4 <a href='#color-rgb' id='QQ2-1-6'>Color (\(\text {RGB}\))</a></span>
<br />    <span class='sectionToc'>5 <a href='#measurement-of-the-redundancy' id='QQ2-1-8'>Measurement of the redundancy</a></span>
<br />    <span class='sectionToc'>6 <a href='#resources' id='QQ2-1-9'>Resources</a></span>
   </div>
<!-- l. 8 --><p class='indent'>   Usually, some part of the data in an image is <a href='https://en.wikipedia.org/wiki/Data_redundancy'>redundant</a> (can be removed without
loss of information).
</p><!-- l. 12 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='statistical-redundancy'><span class='titlemark'>1   </span> <a id='x1-20001'></a>Statistical redundancy</h3>
<!-- l. 14 --><p class='noindent'><a href='https://en.wikipedia.org/wiki/Redundancy_(information_theory)'>Statistical redundancy</a> is present in all those sequences of symbols where we can
infeer a probability of ocurrence of a symbol taking into consideration the rest of
symbols of a sequence. Statistical redudancy can be found in text, audio, image and
video, among other types of signals.
</p><!-- l. 20 --><p class='indent'>   Statistical redundancy can be removed by text compressors.
</p><!-- l. 22 --><p class='indent'>   Statistical redundancy is also called source-coding redundancy <span class='cite'>[<span class='ecbx-1000'>?</span>]</span>.
                                                                  

                                                                  
</p><!-- l. 24 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='temporal'><span class='titlemark'>2   </span> <a id='x1-30002'></a>Temporal</h3>
<!-- l. 25 --><p class='noindent'>Temporal redundancy is shown by sequences of samples when those samples are
similar in value and when paterns of samples tend to repeat. Temporal redundancy is
found in all those time-dependant signals, such as <a href='https://en.wikipedia.org/wiki/Inter_frame'>audio</a> and <a href='https://en.wikipedia.org/wiki/Inter_frame'>video</a>, among
others.
</p><!-- l. 32 --><p class='indent'>   Temporal redundancy can be removed by most audio and video codecs.
</p><!-- l. 34 --><p class='indent'>   Most video codecs use motion compensation to remove temporal redundancy.
</p><!-- l. 36 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='spatial-d'><span class='titlemark'>3   </span> <a id='x1-40003'></a>Spatial (2D)</h3>
<!-- l. 38 --><p class='noindent'><a href='https://robbfoxx.wordpress.com/2015/07/12/discussion-6-2-1-what-is-redundancy-temporal-redundancy-and-spatial-redundancy/'>Spatial redundancy</a> is present basically in images, because pixels tend to be similar to
their neighbors or tend to repeat textures. See Fig <a href='#x1-4001r1'>1<!-- tex4ht:ref: fig:correlacion_lena  --></a>.
</p>
   <figure class='figure'> 

                                                                  

                                                                  
                                                                  

                                                                  
<!-- l. 44 --><p class='noindent' id='-spatial-redundancy-in-images-'><img alt='PIC' src='graphics/correlacion_lena.png' /> <a id='x1-4001r1'></a>
<a id='x1-4002'></a>
</p>
<figcaption class='caption'><span class='id'>Figure 1: </span><span class='content'>Spatial redundancy in images.
</span></figcaption><!-- tex4ht:label?: x1-4001r3  -->
                                                                  

                                                                  
   </figure>
<!-- l. 49 --><p class='indent'>   Humans are more sensitive to low-frequency image data than high-frequency data.
In addition, luminance information is more important than chrominance
information <span class='cite'>[<span class='ecbx-1000'>?</span>]</span>.
</p>
   <h3 class='sectionHead' id='color-rgb'><span class='titlemark'>4   </span> <a id='x1-50004'></a>Color (\(\text {RGB}\))</h3>
<!-- l. 52 --><p class='noindent'>In \(\text {RGB}\) images, the color of a pixel depends on the <a href='https://en.wikipedia.org/wiki/Visible_spectrum'>frequency of the light that the pixel
represents</a>. Such information can be represented in a number of different encoding
systems known as <a href='https://en.wikipedia.org/wiki/Color_space'>color spaces</a>. Among all those systems, the \(\text {RGB}\) color space is the most
used because \(\text {RGB}\) images can be obtained directly from the light signal using color
filters.<span class='footnote-mark'><a href='#fn1x0' id='fn1x0-bk'><sup class='textsuperscript'>1</sup></a></span><a id='x1-5001f1'></a>
</p><!-- l. 62 --><p class='indent'>   The \(\text {RGB}\) color model has evident physical advantages and it is straightforward and
easy to manage, but also, in general, is quite <a href='https://en.wikipedia.org/wiki/Data_redundancy'>redundant</a>. In the case of a \(\text {RGB}\) image, the
three components of each pixel are usually highly <a href='https://en.wikipedia.org/wiki/Correlation_and_dependence'>correlated</a> in the sense that, for
example, if the \(\text {R}\) component of a pixel has a high value, the other components will be
also high, with a high probability. This means that if we use an encoding
system that takes into consideration this redundancy, we can express the same
information<span class='footnote-mark'><a href='#fn2x0' id='fn2x0-bk'><sup class='textsuperscript'>2</sup></a></span><a id='x1-5002f2'></a>
using a smaller number of bits (reducing thus the length of the code-stream).
</p>
   <figure class='figure'> 

                                                                  

                                                                  
                                                                  

                                                                  
<!-- l. 79 --><p class='noindent' id='-effect-visual-of-chroma-subsamplig-in-the-ycrcb-domain-see-this-httpsgithubcomsistemasmultimediasistemasmultimediagithubioblobmastermilestonesyuvcompressionchromasubsamplingipynbnotebook-'><img alt='PIC' src='san-diego_chroma_subsampled.png' /> <a id='x1-5003r2'></a>
<a id='x1-5004'></a>
</p>
<figcaption class='caption'><span class='id'>Figure 2:  </span><span class='content'>Effect  (visual)  of  chroma  subsamplig  in  the  \(\text {YCrCb}\)  domain.  See  this
<a href='https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/milestones/06-YUV_compression/chroma_subsampling.ipynb'>notebook</a>.                                                          </span></figcaption><!-- tex4ht:label?: x1-5003r4  -->
                                                                  

                                                                  
   </figure>
<!-- l. 86 --><p class='indent'>   Visual color redundancy (generated by the way that humans perceive the
chrominance) is exploited by most color models used in image and video compression,
such as \(\text {YCrCb}\) and \(\text {YCoCg}\). This can be see in the Fig. <a href='#x1-5003r2'>2<!-- tex4ht:ref: fig:san-diego_chroma_subsampled  --></a>.
</p>
   <h3 class='sectionHead' id='measurement-of-the-redundancy'><span class='titlemark'>5   </span> <a id='x1-60005'></a>Measurement of the redundancy</h3>
<!-- l. 92 --><p class='noindent'><a href='https://en.wikipedia.org/wiki/Redundancy_(information_theory)'>redundancy</a> we have basically two options:
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-6002x1'>Compute the <a href='https://en.wikipedia.org/wiki/Entropy_(information_theory)'>0-order (memoryless source) entropy</a> of the signal: the higher
     the  entropy,  the  lower  the  redudancy.  In  fact,  if  we  suppose  that  the
     samples of the signal are uncorrelated, the 0-order entropy is an exact
     measure of the expected bit-rate achieved by an <a href='https://en.wikipedia.org/wiki/Arithmetic_coding'>arithmetic encoder</a> (the
     most efficient entropy compressor). Unfortunately, the 0-order entropy is
     usually only a estimation of the redundancy, i.e., lower bit-rates can be
     achieved in practice after using a high-order decorrelation.
     </li>
<li class='enumerate' id='x1-6004x2'>A better way is to use an <a href='https://en.wikipedia.org/wiki/Data_compression'>lossless compressor</a>: the higher the length of the
     compressed file compared to the length of the original file, the lower the
     redundancy.<span class='footnote-mark'><a href='#fn3x0' id='fn3x0-bk'><sup class='textsuperscript'>3</sup></a></span><a id='x1-6005f3'></a>
     Notice,  however,  that  although  this  estimation  is  more  accurate  than
     the 0-order entropy, in general, it depends on the compressor (different
     algoritms can provide different estimations).</li></ol>
<!-- l. 120 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='resources'><span class='titlemark'>6   </span> <a id='x1-70006'></a>Resources</h3>
   <div class='footnotes'><!-- l. 60 --><p class='indent'>     <span class='footnote-mark'><a href='#fn1x0-bk' id='fn1x0'><sup class='textsuperscript'>1</sup></a></span><span class='ecrm-0800'>Specifically, a red (R) filter, a green (G) filter and a blue (B) filter.</span></p>
<!-- l. 73 --><p class='indent'>     <span class='footnote-mark'><a href='#fn2x0-bk' id='fn2x0'><sup class='textsuperscript'>2</sup></a></span><span class='ecrm-0800'>Or almost the same amount of information, depending on the accuracy of the
</span><span class='ecrm-0800'>computations.</span></p>
<!-- l. 113 --><p class='noindent'><span class='footnote-mark'><a href='#fn3x0-bk' id='fn3x0'><sup class='textsuperscript'>3</sup></a></span><span class='ecrm-0800'>If the length of the compressed file is equal or larger than the length of the original
</span><span class='ecrm-0800'>file,  then,  for  the  compressor  that  we  are  using,  there  is  not  redundancy  in  the  original
</span><span class='ecrm-0800'>representation.</span></p>                                                                                                      </div>
 
</body> 
</html>