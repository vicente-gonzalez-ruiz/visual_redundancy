<!DOCTYPE html> 
<html lang='en-US' xml:lang='en-US'> 
<head> <title>Visual Redundancy</title> 
<meta charset='utf-8' /> 
<meta content='TeX4ht (https://tug.org/tex4ht/)' name='generator' /> 
<meta content='width=device-width,initial-scale=1' name='viewport' /> 
<link href='index.css' rel='stylesheet' type='text/css' /> 
<meta content='index.tex' name='src' /> 
<script>window.MathJax = { tex: { tags: "ams", }, }; </script> 
 <script async='async' id='MathJax-script' src='https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js' type='text/javascript'></script>  
</head><body>
   <div class='maketitle'>
                                                                  

                                                                  
                                                                  

                                                                  

<h2 class='titleHead'>Visual Redundancy</h2>
 <div class='author'><span class='ecrm-1200'>Vicente González Ruiz</span></div><br />
<div class='date'><span class='ecrm-1200'>July 5, 2022</span></div>
   </div>
   <h3 class='likesectionHead' id='contents'><a id='x1-1000'></a>Contents</h3>
   <div class='tableofcontents'>
    <span class='sectionToc'>1 <a href='#color-rgb' id='QQ2-1-2'>Color (\(\text {RGB}\))</a></span>
<br />    <span class='sectionToc'>2 <a href='#spatial-d' id='QQ2-1-4'>Spatial (2D)</a></span>
<br />    <span class='sectionToc'>3 <a href='#temporal' id='QQ2-1-6'>Temporal</a></span>
<br />    <span class='sectionToc'>4 <a href='#resources' id='QQ2-1-7'>Resources</a></span>
   </div>
<!-- l. 8 --><p class='indent'>   Usually, some part of the data in an image is <a href='https://en.wikipedia.org/wiki/Data_redundancy'>redundant</a> (can be removed without
loss of information).
</p><!-- l. 13 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='color-rgb'><span class='titlemark'>1   </span> <a id='x1-20001'></a>Color (\(\text {RGB}\))</h3>
<!-- l. 14 --><p class='noindent'>In \(\text {RGB}\) images, the color of a pixel depends on the <a href='https://en.wikipedia.org/wiki/Visible_spectrum'>frequency of the light that the pixel
represents</a>. Such information can be represented in a number of different encoding
systems known as <a href='https://en.wikipedia.org/wiki/Color_space'>color spaces</a>. Among all those systems, the \(\text {RGB}\) color space is the most
used because \(\text {RGB}\) images can be obtained directly from the light signal using color
filters.<span class='footnote-mark'><a href='#fn1x0' id='fn1x0-bk'><sup class='textsuperscript'>1</sup></a></span><a id='x1-2001f1'></a>
</p><!-- l. 24 --><p class='indent'>   The \(\text {RGB}\) color model has evident physical advantages and it is straightforward and
easy to manage, but also, in general, is quite <a href='https://en.wikipedia.org/wiki/Data_redundancy'>redundant</a>. In the case of a \(\text {RGB}\) image, the
three components of each pixel are usually highly <a href='https://en.wikipedia.org/wiki/Correlation_and_dependence'>correlated</a> in the sense that, for
example, if the \(\text {R}\) component of a pixel has a high value, the other components will be
also high, with a high probability. This means that if we use an encoding
system that takes into consideration this redundancy, we can express the same
                                                                  

                                                                  
information<span class='footnote-mark'><a href='#fn2x0' id='fn2x0-bk'><sup class='textsuperscript'>2</sup></a></span><a id='x1-2002f2'></a>
using a smaller number of bits (reducing thus the length of the code-stream).
</p>
   <figure class='figure'> 

                                                                  

                                                                  
                                                                  

                                                                  
<!-- l. 41 --><p class='noindent' id='-effect-visual-of-chroma-subsamplig-in-the-ycrcb-domain-see-this-httpsgithubcomvicentegonzalezruizvisualredundancyblobmasterchromasubsamplingipynbnotebook-'><img alt='PIC' src='san-diego_chroma_subsampled.png' /> <a id='x1-2003r1'></a>
<a id='x1-2004'></a>
</p>
<figcaption class='caption'><span class='id'>Figure 1:  </span><span class='content'>Effect  (visual)  of  chroma  subsamplig  in  the  \(\text {YCrCb}\)  domain.  See  this
<a href='https://github.com/vicente-gonzalez-ruiz/visual_redundancy/blob/master/chroma_subsampling.ipynb'>notebook</a>.                                                          </span></figcaption><!-- tex4ht:label?: x1-2003r1  -->
                                                                  

                                                                  
   </figure>
<!-- l. 48 --><p class='indent'>   Visual color redundancy (generated by the way that humans perceive the
chrominance) is exploited by most color models used in image and video compression,
such as \(\text {YCrCb}\) and \(\text {YCoCg}\). This can be see in the Fig. <a href='#x1-2003r1'>1<!-- tex4ht:ref: fig:san-diego_chroma_subsampled  --></a>.
</p>
   <h3 class='sectionHead' id='spatial-d'><span class='titlemark'>2   </span> <a id='x1-30002'></a>Spatial (2D)</h3>
<!-- l. 55 --><p class='noindent'><a href='https://robbfoxx.wordpress.com/2015/07/12/discussion-6-2-1-what-is-redundancy-temporal-redundancy-and-spatial-redundancy/'>Spatial redundancy</a> is present basically in images, because pixels tend to be similar to
their neighbors or tend to repeat textures. See Fig <a href='#x1-3001r2'>2<!-- tex4ht:ref: fig:correlacion_lena  --></a>.
</p>
   <figure class='figure'> 

                                                                  

                                                                  
                                                                  

                                                                  
<!-- l. 61 --><p class='noindent' id='-spatial-redundancy-in-images-'><img alt='PIC' src='graphics/correlacion_lena.png' /> <a id='x1-3001r2'></a>
<a id='x1-3002'></a>
</p>
<figcaption class='caption'><span class='id'>Figure 2: </span><span class='content'>Spatial redundancy in images.
</span></figcaption><!-- tex4ht:label?: x1-3001r2  -->
                                                                  

                                                                  
   </figure>
<!-- l. 66 --><p class='indent'>   Humans are more sensitive to low-frequency image data than high-frequency data.
In addition, luminance information is more important than chrominance
information <span class='cite'>[<a href='#Xkondoz2009visual'>1</a>]</span>.
</p>
   <h3 class='sectionHead' id='temporal'><span class='titlemark'>3   </span> <a id='x1-40003'></a>Temporal</h3>
<!-- l. 71 --><p class='noindent'>Temporal redundancy is shown by sequences of samples when those samples are
similar in value and when paterns of samples tend to repeat. Temporal redundancy is
found in all those time-dependant signals, such as <a href='https://en.wikipedia.org/wiki/Inter_frame'>audio</a> and <a href='https://en.wikipedia.org/wiki/Inter_frame'>video</a>, among
others.
</p><!-- l. 78 --><p class='indent'>   Temporal redundancy can be removed by most audio and video codecs.
</p><!-- l. 80 --><p class='indent'>   Most video codecs use motion compensation to remove temporal redundancy.
</p><!-- l. 82 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='resources'><span class='titlemark'>4   </span> <a id='x1-50004'></a>Resources</h3>
   <div class='thebibliography'>
   <p class='bibitem'><span class='biblabel'>
 [1]<span class='bibsp'>   </span></span><a id='Xkondoz2009visual'></a>Ahmet Kondoz. <a href='https://vdoc.pub/download/visual-media-coding-and-transmission-3k0ci7rtoeug'><span class='ecti-1000'>Visual Media Coding and Transmission</span></a>. John Wiley &amp;
   Sons, 2009.
</p>
   </div>
   <div class='footnotes'><!-- l. 22 --><p class='indent'>     <span class='footnote-mark'><a href='#fn1x0-bk' id='fn1x0'><sup class='textsuperscript'>1</sup></a></span><span class='ecrm-0800'>Specifically, a red (R) filter, a green (G) filter and a blue (B) filter.</span></p>
<!-- l. 35 --><p class='indent'>     <span class='footnote-mark'><a href='#fn2x0-bk' id='fn2x0'><sup class='textsuperscript'>2</sup></a></span><span class='ecrm-0800'>Or almost the same amount of information, depending on the accuracy of the
</span><span class='ecrm-0800'>computations.</span></p>                                                                                                       </div>
 
</body> 
</html>