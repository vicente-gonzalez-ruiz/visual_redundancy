% Poner en perception (sonido, luz). ??

\title{Visual Redundancy}

\maketitle
\tableofcontents

Usually, some part of the data in an image is
\href{https://en.wikipedia.org/wiki/Data_redundancy}{redundant} (can
be removed without loss of information).


\section{Color ($\text{RGB}$)}
In $\text{RGB}$ images, the color of a pixel depends on the
\href{https://en.wikipedia.org/wiki/Visible_spectrum}{frequency of the
  light that the pixel represents}. Such information can be
represented in a number of different encoding systems known as
\href{https://en.wikipedia.org/wiki/Color_space}{color spaces}. Among
all those systems, the $\text{RGB}$ color space is the most used
because $\text{RGB}$ images can be obtained directly from the light
signal using color filters.\footnote{Specifically, a red (R) filter, a
green (G) filter and a blue (B) filter.}

The $\text{RGB}$ color model has evident physical advantages and it is
straightforward and easy to manage, but also, in general, is quite
\href{https://en.wikipedia.org/wiki/Data_redundancy}{redundant}. In
the case of a $\text{RGB}$ image, the three components of each pixel
are usually highly
\href{https://en.wikipedia.org/wiki/Correlation_and_dependence}{correlated}
in the sense that, for example, if the $\text{R}$ component of a pixel
has a high value, the other components will be also high, with a high
probability. This means that if we use an encoding system that takes
into consideration this redundancy, we can express the same
information\footnote{Or almost the same amount of information,
depending on the accuracy of the computations.} using a smaller number
of bits (reducing thus the length of the code-stream).

\begin{figure}
  \centering
  %\png{san-diego_chroma_subsampled}{1000}
  \includegraphics{san-diego_chroma_subsampled}
  \caption{Effect (visual) of chroma subsamplig in the $\text{YCrCb}$ domain. See
    this
    \href{https://github.com/vicente-gonzalez-ruiz/visual_redundancy/blob/master/chroma_subsampling.ipynb}{notebook}.}
  \label{fig:san-diego_chroma_subsampled}
\end{figure}

Visual color redundancy (generated by the way that humans perceive the
chrominance) is exploited by most color models used in image and video
compression, such as $\text{YCrCb}$ and $\text{YCoCg}$. This can be
see in the Fig.~\ref{fig:san-diego_chroma_subsampled}.

\section{Chroma redundancy}

Humans do not perceive detail in the chrominance as well as in they
does in the
luminance.~\cite{vruiz__visual_redundancy,burger2016digital}. Consecuently,
the
\href{https://en.wikipedia.org/wiki/Sampling_(signal_processing)}{sampling
  rate} used in the chrominance can be generally reduced to 1/4 of the
used for the luminance without a noticeable distortion (see
Fig.~\ref{fig:san-diego_chroma_subsampled}). This
\href{https://en.wikipedia.org/wiki/Bandwidth_(computing)}{fact is
  used when compressing} digital still images and is one of the reason
why, for example, the \href{https://en.wikipedia.org/wiki/JPEG}{JPEG}
image compressor converts $\text{RGB}$ images to the $\text{YCrCb}$
color domain~\cite{vruiz__YCrCb}.

\section{Spatial (2D)}
\href{https://robbfoxx.wordpress.com/2015/07/12/discussion-6-2-1-what-is-redundancy-temporal-redundancy-and-spatial-redundancy/}{Spatial
  redundancy} is present basically in images, because pixels tend to
be similar to their neighbors or tend to repeat textures. See
Fig~\ref{fig:correlacion_lena}.

\begin{figure}
  %\pngfig{graphics/correlacion_lena}{8cm}{800} %
  \includegraphics{graphics/correlacion_lena}
  \caption{Spatial redundancy in images.}
  \label{fig:correlacion_lena}
\end{figure}

Humans are more sensitive to low-frequency image data than
high-frequency data. In addition, luminance information is more
important than chrominance information~\cite{kondoz2009visual}.

\section{Temporal}
Temporal redundancy is shown by sequences of samples when those
samples are similar in value and when paterns of samples tend to
repeat. Temporal redundancy is found in all those time-dependant
signals, such as
\href{https://en.wikipedia.org/wiki/Inter_frame}{audio} and
\href{https://en.wikipedia.org/wiki/Inter_frame}{video}, among others.

Temporal redundancy can be removed by most audio and video codecs.

Most video codecs use motion compensation to remove temporal redundancy.

\section{Resources}
\renewcommand{\addcontentsline}[3]{}% Remove functionality of \addcontentsline
\bibliography{maths,data-compression,signal-processing,DWT,image-compression,image-processing}
