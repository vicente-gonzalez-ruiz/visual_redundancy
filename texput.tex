% Poner en perception (sonido, luz). ??

\title{Visual Redundancy}

\maketitle
\tableofcontents

Usually, some part of the data in an image is
\href{https://en.wikipedia.org/wiki/Data_redundancy}{redundant} (can
be removed without loss of information).

\section{Statistical redundancy}
\href{https://en.wikipedia.org/wiki/Redundancy_(information_theory)}{Statistical
  redundancy} is present in all those sequences of symbols where we
can infeer a probability of ocurrence of a symbol taking into
consideration the rest of symbols of a sequence. Statistical redudancy
can be found in text, audio, image and video, among other types of
signals.

Statistical redundancy can be removed by text compressors.

Statistical redundancy is also called source-coding redundancy~\cite{kondoz2009visual}.

\section{Temporal}
Temporal redundancy is shown by sequences of samples when those
samples are similar in value and when paterns of samples tend to
repeat. Temporal redundancy is found in all those time-dependant
signals, such as
\href{https://en.wikipedia.org/wiki/Inter_frame}{audio} and
\href{https://en.wikipedia.org/wiki/Inter_frame}{video}, among others.

Temporal redundancy can be removed by most audio and video codecs.

Most video codecs use motion compensation to remove temporal redundancy.

\section{Spatial (2D)}
\href{https://robbfoxx.wordpress.com/2015/07/12/discussion-6-2-1-what-is-redundancy-temporal-redundancy-and-spatial-redundancy/}{Spatial
  redundancy} is present basically in images, because pixels tend to
be similar to their neighbors or tend to repeat textures. See
Fig~\ref{fig:correlacion_lena}.

\begin{figure}
  \pngfig{graphics/correlacion_lena}{8cm}{800} %
  \caption{Spatial redundancy in images.}
  \label{fig:correlacion_lena}
\end{figure}

Humans are more sensitive to low-frequency image data than high-frequency data. In addition, luminance information is more important than chrominance information~\cite{kondoz2009visual}.

\section{Color ($\text{RGB}$)}
In $\text{RGB}$ images, the color of a pixel depends on the
\href{https://en.wikipedia.org/wiki/Visible_spectrum}{frequency of the
  light that the pixel represents}. Such information can be
represented in a number of different encoding systems known as
\href{https://en.wikipedia.org/wiki/Color_space}{color spaces}. Among
all those systems, the $\text{RGB}$ color space is the most used
because $\text{RGB}$ images can be obtained directly from the light
signal using color filters.\footnote{Specifically, a red (R) filter, a
green (G) filter and a blue (B) filter.}

The $\text{RGB}$ color model is straightforward and easy to manage,
but also, in general, is quite
\href{https://en.wikipedia.org/wiki/Data_redundancy}{redundant}. In
the case of a $\text{RGB}$ image, the three components of each pixel
are usually highly
\href{https://en.wikipedia.org/wiki/Correlation_and_dependence}{correlated}
in the sense that, for example, if the $\text{R}$ component of a pixel
has a high value, the other components will be also high. This means
that if we use an encoding system that takes into consideration this
redundancy, we can express the same information\footnote{Or almost the
same amount of information, depending on the accuracy of the
computations.} using a smaller number of bits (reducing thus the
length of the code-stream).


%\bibliography{video-compression}
